# ğŸ¤– Hand Gesture Recognition for Sign Language Communication

A Final Year Project that translates American Sign Language (ASL) gestures into text/speech and vice versa using Deep Learning and Computer Vision. This system improves communication for hearing-impaired individuals using a real-time bidirectional interface.

---

## ğŸ“‚ Dataset Access

Due to file size limits on GitHub, the dataset used for training and testing is hosted on Google Drive.

ğŸ“¥ **[Click here to download the dataset for Hand Sign](https://drive.google.com/drive/folders/1yBXH6Zrcep7F0jpB7UOyxJzoYoiOcU8m)**

ğŸ“¥ **[Click here to download the dataset for Voice Process](https://drive.google.com/drive/folders/1jl_iy0CRS4hsVlHD5J_RLnauXqvP7NwH)**

> âš ï¸ Make sure to download and extract the dataset into the project directory before training or testing the model.

---

## ğŸ“Œ Project Highlights

- ğŸ”¤ **ASL Gesture to Text/Speech**: Recognizes 28 hand gestures using a trained MobileNetV2 model and translates them into readable text and audio.
- ğŸ—£ï¸ **Voice to Sign Animation**: Converts spoken English words to corresponding sign language animations using cartoon-based characters.
- ğŸ¥ **Real-Time Hand Tracking**: Uses MediaPipe for efficient hand landmark detection from webcam feed.
- ğŸ› ï¸ **Command-Line Interface**: A simple menu-driven CLI for smooth interaction and testing.

---

## ğŸ—‚ï¸ Folder Structure
â”œâ”€â”€ asl_model_mobilenetv2.h5 # Trained model for ASL recognition
â”œâ”€â”€ data_collect.py # Script to collect gesture images
â”œâ”€â”€ train.py # Model training script
â”œâ”€â”€ main.py # Main execution: ASL gesture to text/speech
â”œâ”€â”€ voiceto sign.py # Voice input converted to animated sign output
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Hand Gesture Recognition Report.pdf # Detailed project documentation
â”œâ”€â”€ PPT.pptx # Presentation slide deck
â””â”€â”€ README.md # Project description (this file)

1. Install Dependencies

pip install -r requirements.txt

2. Run the Application

# To collect your own gesture data
python data_collect.py

# To train your own model
python train.py

# To recognize gestures and convert to text/speech
python main.py

# To convert voice to sign animation
python "voiceto sign.py"

## ğŸ§  Technologies Used
Python

TensorFlow / Keras

OpenCV

MediaPipe

MobileNetV2

pyttsx3 (Text-to-Speech)

## ğŸ“Š Results
Accuracy: 90%+ on test dataset of 28 ASL signs.

Real-time classification with smooth webcam performance.

Lightweight model deployable on standard devices.

## âœ¨ Future Enhancements
Add more gesture classes for complete ASL vocabulary.

Include multi-hand and dynamic gesture recognition.

Mobile/web deployment with TensorFlow Lite or ONNX.

## ğŸ™‹â€â™€ï¸ Author
DHARMA DEVI K
Final Year Student, B.Tech - Information Technology
Arulmigu Meenakshi Amman College of Engineering
